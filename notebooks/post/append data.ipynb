{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get anndata object from util file \n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import squidpy as sq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numba\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_anndata(path):\n",
    "    \n",
    "    img = skimage.io.imread(path)\n",
    "    ski_img = skimage.measure.regionprops(img)\n",
    "    df = pd.DataFrame(ski_img)\n",
    "    var_array = df.head(1).values\n",
    "    list_var = list(var_array.flatten())\n",
    "    labels = len(ski_img)\n",
    "    df = pd.DataFrame(index = list_var, columns = np.arange(1,labels,1))\n",
    "\n",
    "    \n",
    "    for ind in df.index:\n",
    "        for val in df.columns:\n",
    "            df.loc[ind,val] = getattr(ski_img[val],ind)\n",
    "            \n",
    "    for val in df.columns:\n",
    "        df.loc['bbox',val] = np.asarray(df.loc['bbox',val]).reshape(1,4)\n",
    "        \n",
    "        \n",
    "    for val in df.columns:\n",
    "        df.loc['centroid',val] = np.asarray(df.loc['centroid',val]).reshape(1,2)\n",
    "        \n",
    "        \n",
    "    for ind in df.index:\n",
    "        for val in df.columns:\n",
    "            if type(df.loc[ind,val]) == np.ndarray:\n",
    "                df.loc[ind,val] = df.loc[ind,val][~np.isnan(df.loc[ind,val])].flatten()\n",
    "                \n",
    "                \n",
    "                \n",
    "    scalar_list = ['area','area_bbox','area_convex','area_filled','axis_major_length','axis_minor_length',\n",
    "            'eccentricity', 'equivalent_diameter_area','euler_number','extent','feret_diameter_max',\n",
    "              'label','orientation','perimeter','perimeter_crofton','solidity'] \n",
    "    scalar_df = df.loc[['area','area_bbox','area_convex','area_filled','axis_major_length','axis_minor_length',\n",
    "            'eccentricity', 'equivalent_diameter_area','euler_number','extent','feret_diameter_max',\n",
    "              'label','orientation','perimeter','perimeter_crofton','solidity']]\n",
    "                   \n",
    "    multidim_list = ['bbox','centroid','centroid_local', 'coords', 'image', 'image_convex', 'image_filled',\n",
    "                'inertia_tensor', 'inertia_tensor_eigvals', 'moments', 'moments_central' ,'moments_hu',\n",
    "                'moments_normalized']\n",
    "    multidim_df = df.loc[['bbox','centroid','centroid_local', 'coords', 'image', 'image_convex', 'image_filled',\n",
    "                'inertia_tensor', 'inertia_tensor_eigvals', 'moments', 'moments_central' ,'moments_hu',\n",
    "                'moments_normalized']]\n",
    "    \n",
    "    \n",
    "\n",
    "    mt = multidim_df.transpose()\n",
    "    \n",
    "    X = scalar_df.T.values\n",
    "    adata = ad.AnnData(X)\n",
    "    adata.var_names = scalar_df.index\n",
    "    adata.obs_names = scalar_df.columns\n",
    "    adata.var = pd.DataFrame(index = scalar_list, columns = scalar_list)\n",
    "    adata.obs = pd.DataFrame(index = scalar_df.columns, columns = scalar_df.columns)\n",
    "    for col in mt.columns:\n",
    "        adata.obsm[col] = mt[col].values\n",
    "        \n",
    "    i = 0\n",
    "    for row in multidim_list:\n",
    "        adata.uns[row] = multidim_df.iloc[[i]].values.flatten()\n",
    "        i = i+1\n",
    "        \n",
    "    return adata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dictionary \n",
    "import pickle \n",
    "with open('mean_intensities.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key convert\n",
    "index_558 = ['LMNB1_8028', 'LMNB1_8028','LMNB1_8028','LMNB1_8028']\n",
    "index_610 = ['ELAVL2','IBA1','PVALB', 'PDGFRA']\n",
    "index_687 = ['GFAP','MAP2','NFH','MBP']\n",
    "\n",
    "delete_entries = ['one_z_plane_558_2_8028', 'one_z_plane_558_3_8028','one_z_plane_558_4_8028']\n",
    "\n",
    "del loaded_dict['one_z_plane_558_2_8028']\n",
    "del loaded_dict['one_z_plane_558_3_8028']\n",
    "del loaded_dict['one_z_plane_558_4_8028']\n",
    "\n",
    "loaded_dict['LMNB1'] = loaded_dict.pop('one_z_plane_558_1_8028')\n",
    "loaded_dict['ELAVL2'] = loaded_dict.pop('one_z_plane_610_1_8028')\n",
    "loaded_dict['IBA1'] = loaded_dict.pop('one_z_plane_610_2_8028')\n",
    "loaded_dict['PVALB'] = loaded_dict.pop('one_z_plane_610_3_8028')\n",
    "loaded_dict['PDGFRA'] = loaded_dict.pop('one_z_plane_610_4_8028')\n",
    "loaded_dict['GFAP'] = loaded_dict.pop('one_z_plane_687_1_8028')\n",
    "loaded_dict['MAP2'] = loaded_dict.pop('one_z_plane_687_2_8028')\n",
    "loaded_dict['NFH'] = loaded_dict.pop('one_z_plane_687_3_8028')\n",
    "loaded_dict['MBP'] = loaded_dict.pop('one_z_plane_687_4_8028')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_nan(arr):\n",
    "    del_list = []\n",
    "    mask = np.isnan(arr)\n",
    "    for m,v in zip(mask, range(len(mask))):\n",
    "        if m == True:\n",
    "            del_list.append(v)\n",
    "        \n",
    "    arr = np.delete(arr,del_list)\n",
    "    return(arr)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in loaded_dict.keys():\n",
    "    val = loaded_dict[key]\n",
    "    val = del_nan(val)\n",
    "    #val = np.roll(val,-1)\n",
    "    loaded_dict.update({key:val[1:]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/anndata/_core/anndata.py:875: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    [1, 2, 3, 4, 5]\n",
      "\n",
      "    Inferred to be: integer\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n",
      "/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/anndata/_core/anndata.py:801: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    [1, 2, 3, 4, 5]\n",
      "\n",
      "    Inferred to be: integer\n",
      "\n",
      "  value_idx = self._prep_dim_index(value.index, attr)\n"
     ]
    }
   ],
   "source": [
    "ad_object   = return_anndata('/gpfs/commons/groups/nygcfaculty/PySeq/20210428_mouse_genotype_2/segmented_sections/m387ntga2_labels.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = ad_object.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in loaded_dict.keys():\n",
    "    mat = np.append(mat, np.asarray([loaded_dict[key]]).transpose(), axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remake new anndata object\n",
    "adt = ad.AnnData(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = ad_object.var_names\n",
    "var = list(lis)\n",
    "post_var = list(loaded_dict.keys())\n",
    "var.extend(post_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt.var_names = var\n",
    "adt.obs_names = np.arange(1,np.shape(mat)[0] + 1,1)\n",
    "#adt.obsm = ad_object.obsm\n",
    "adt.uns = ad_object.uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in adt.uns.keys():\n",
    "    #adt.obsm[j] = np.array2string(adt.obsm[j])\n",
    "    adt.uns[j] = np.array2string(adt.uns[j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11169, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ad_object.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(adt.obs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt.obs.columns = adt.obs.columns.astype(str)\n",
    "adt.var.columns = adt.var.columns.astype(str)\n",
    "adt.write('/gpfs/commons/groups/nygcfaculty/PySeq/spatial_analysis/m387ntga2_labels_anndata_sample.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adt\u001b[38;5;241m.\u001b[39muns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43madt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36marray2string\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/spatial/lib/python3.9/site-packages/numpy/core/arrayprint.py:689\u001b[0m, in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[1;32m    686\u001b[0m     options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(suffix)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# treat as a null array if any of shape elements == 0\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _array2string(a, options, separator, prefix)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "adt.uns['bbox'] = np.array2string(adt.uns['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/anndata/_core/anndata.py:120: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "add = ad.read_h5ad('/gpfs/commons/groups/nygcfaculty/PySeq/spatial_analysis/m387ntga2_labels_anndata_sample.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt.write_zarr('/gpfs/commons/groups/nygcfaculty/PySeq/spatial_analysis/m387ntga2_labels_anndata_sample.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'tobytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#####ROUGH WORK #####\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m adt\u001b[38;5;241m.\u001b[39muns\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#adt.obsm[j] = np.array2string(adt.obsm[j])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     adt\u001b[38;5;241m.\u001b[39muns[j] \u001b[38;5;241m=\u001b[39m \u001b[43madt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'tobytes'"
     ]
    }
   ],
   "source": [
    "######### ROUGH WORK #####\n",
    "for j in adt.uns.keys():\n",
    "    #adt.obsm[j] = np.array2string(adt.obsm[j])\n",
    "    adt.uns[j] = adt.uns[j].tobytes()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask==2022.5.2\n",
      "matplotlib==3.5.2\n",
      "numpy==1.21.5\n",
      "pandas==1.4.3\n",
      "squidpy==1.2.2\n",
      "numba==0.55.1\n",
      "anndata==0.7.8\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "spatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
