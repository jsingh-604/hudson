{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "import anndata\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "from pyseq import image_analysis as ia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dask.distributed import Client\n",
    "import numba\n",
    "from os import makedirs, getcwd\n",
    "import joblib\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import skimage\n",
    "import time\n",
    "from os.path import exists, join\n",
    "from dask.distributed import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(queue_name = 'pe2', log_dir=None):\n",
    "    \"\"\" Make dask cluster w/ workers = 2 cores, 32 G mem, and 1 hr wall time.\n",
    "\n",
    "        return cluster, client\n",
    "    \"\"\"\n",
    "    if log_dir is None:\n",
    "        log_dir = join(getcwd(),'dask_logs')\n",
    "        makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    cluster = SLURMCluster(\n",
    "                queue = queue_name, \n",
    "                cores = 6 ,\n",
    "                memory = '48G',\n",
    "                log_directory=log_dir)\n",
    "                #extra=[\"--lifetime\", \"55m\", \"--lifetime-stagger\", \"4m\"])\n",
    "    client = Client(cluster, timeout=\"50s\")\n",
    "\n",
    "    return cluster, client\n",
    "\n",
    "cluster, client = get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://10.4.200.80:8787/status'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_cluster(count): \n",
    "    cluster.scale(count)\n",
    "    return cluster.dashboard_link\n",
    "scale_cluster(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import core, utils, io, models, metrics\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 16:49:10,500 [INFO] WRITING LOG OUTPUT TO /gpfs/commons/home/jsingh/.cellpose/run.log\n",
      "2022-07-15 16:49:10,503 [INFO] >> TN2 << model set to be used\n",
      "2022-07-15 16:49:10,505 [INFO] >>>> using CPU\n",
      "2022-07-15 16:49:11,131 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    }
   ],
   "source": [
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "model = models.CellposeModel(model_type='TN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageAnalysis::Opened m387ntga2 \n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "im = ia.get_HiSeqImages(image_path = '/gpfs/commons/home/jsingh/zarrs/m387ntga2.zarr')\n",
    "labels = skimage.io.imread('/gpfs/commons/groups/nygcfaculty/PySeq/20210428_mouse_genotype_2/segmented_sections/m387ntga2_labels.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_z_plane = im.im.sel(obj_step = 8498, channel = 558, cycle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = dask.array.from_array(one_z_plane.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs[6000:8000, 6000:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(image):\n",
    "    channels = [[0,0]]\n",
    "    masks, flows, styles = model.eval(image, diameter=None, channels=channels)\n",
    "    return flows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 16:50:51,577 [INFO] No cell pixels found.\n"
     ]
    }
   ],
   "source": [
    "out = dask.array.map_blocks(model_evaluation,imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(imgs, diameter=None, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 8 B </td>\n",
       "                        <td> 8.0 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> () </td>\n",
       "                        <td> () </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Tasks </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> object </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<model_evaluation, shape=(), dtype=object, chunksize=(), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, flows, styles = dask.compute(model.eval(arr, diameter=None, channels=channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.distributed.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.init_process_group(backend = 'gloo', rank = 0,  world_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.delayed as delayed\n",
    "import ClusterWrap\n",
    "import time\n",
    "from cellpose import models\n",
    "\n",
    "\n",
    "def distributed_eval(\n",
    "    image,\n",
    "    blocksize,\n",
    "    mask=None,\n",
    "    preprocessing_steps=[],\n",
    "    model_kwargs={},\n",
    "    eval_kwargs={},\n",
    "    cluster_kwargs={},\n",
    "):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # set eval defaults\n",
    "    if 'diameter' not in eval_kwargs.keys():\n",
    "        eval_kwargs['diameter'] = 30\n",
    "\n",
    "    # compute overlap\n",
    "    overlap = eval_kwargs['diameter'] * 2\n",
    "\n",
    "    # compute mask to array ratio\n",
    "    if mask is not None:\n",
    "        ratio = np.array(mask.shape) / image.shape\n",
    "\n",
    "    # pipeline to run on each block\n",
    "    def preprocess_and_segment(block, mask=None, block_info=None):\n",
    "\n",
    "        # get block origin\n",
    "        origin = np.array(block_info[0]['chunk-location'])\n",
    "        origin = origin * blocksize - overlap\n",
    "\n",
    "        # check mask foreground\n",
    "        if mask is not None:\n",
    "            mo = np.round(origin * ratio).astype(np.uint16)\n",
    "            mo = np.maximum(0, mo)\n",
    "            ms = np.round(blocksize * ratio).astype(np.uint16)\n",
    "            mask_block = mask[mo[0]:mo[0]+ms[0],\n",
    "                              mo[1]:mo[1]+ms[1],\n",
    "                              mo[2]:mo[2]+ms[2],]\n",
    "\n",
    "            # if there is no foreground, return null result\n",
    "            if np.sum(mask_block) < 1:\n",
    "                return np.zeros(block.shape, dtype=np.int64)\n",
    "\n",
    "        # run preprocessing steps\n",
    "        image = np.copy(block)\n",
    "        for pp_step in preprocessing_steps:\n",
    "            image = pp_step[0](image, **pp_step[1])\n",
    "\n",
    "        # segment\n",
    "        model = models.Cellpose(**model_kwargs)\n",
    "        return model.eval(image, **eval_kwargs)[0]\n",
    "\n",
    "    # start cluster\n",
    "    with ClusterWrap.cluster(**cluster_kwargs) as cluster:\n",
    "\n",
    "        # wrap dataset as a dask object\n",
    "        if isinstance(image, np.ndarray):\n",
    "            future = cluster.client.scatter(image)\n",
    "            image_da = da.from_delayed(\n",
    "                future, shape=image.shape, dtype=image.dtype,\n",
    "            )\n",
    "            image_da = image_da.rechunk(blocksize)\n",
    "            image_da.persist()\n",
    "            time.sleep(30)  ### a little time for workers to be allocated\n",
    "            cluster.client.rebalance()\n",
    "    \n",
    "        # a full dataset as a zarr array\n",
    "        else:\n",
    "            image_da = da.from_array(image, chunks=blocksize)\n",
    "\n",
    "        # wrap mask\n",
    "        mask_d = delayed(mask) if mask is not None else None\n",
    "\n",
    "        # distribute\n",
    "        # TODO: RESULT SHOULD BE WRITTEN TO ZARR\n",
    "        #    OR RETURN DASK ARRAY AND HAVE AN EXECUTE FUNCTION\n",
    "        #    WITH COMPUTE OR TO_ZARR OPTIONS\n",
    "        segmentation = da.map_overlap(\n",
    "            preprocess_and_segment, image_da,\n",
    "            mask=mask_d,\n",
    "            depth=overlap,\n",
    "            dtype=np.int64,\n",
    "            boundary=0,\n",
    "            trim=False,\n",
    "            chunks=[x+2*overlap for x in blocksize],\n",
    "        ).compute()\n",
    "\n",
    "        # TODO: STITCH!\n",
    "\n",
    "        # return result\n",
    "        return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ClusterWrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "spatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
